{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic v1.0\n",
    "\n",
    " 1. [Preliminaries](#preliminaries)  \n",
    "   1.1 [Load libraries](#libraries)  \n",
    "   1.2 [Load data](#load-data)  \n",
    "   1.3 [Combine Data](#combine)  \n",
    "   1.4 [Check for NaN's](#check-nan)\n",
    " 2. [Feature engineering](#feature-eng)  \n",
    "   2.1 [Column \"Name\"](#name)  \n",
    "   2.2 [Column \"Ticket\"](#ticket)  \n",
    "   2.3 [Column \"Cabin\"](#cabin)  \n",
    "   2.5 [Variable encoding](#encoding)  \n",
    "   2.6 [Before and after](#before-after)  \n",
    "   2.6 [Split data](#split-data)  \n",
    " 3. [Model](#model)  \n",
    "   3.1 [Cross validation](#cv)  \n",
    "   3.2 [Fitting](#fitting)\n",
    " 4. [Submission](#submission)  \n",
    "   4.1 [File preparation](#sub-file)  \n",
    "   4.2 [Score](#score)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preliminaries'></a>\n",
    "## 1 - Preliminaries\n",
    "\n",
    "<a id='libraries'></a>\n",
    "### 1.1 - Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "\n",
    "### 1.2 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train_raw shape = (891, 12)\n",
      "df_test_raw shape = (418, 11)\n"
     ]
    }
   ],
   "source": [
    "df_train_raw = pd.read_csv('train.csv')\n",
    "df_test_raw = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"df_train_raw shape =\", df_train_raw.shape)\n",
    "print(\"df_test_raw shape =\", df_test_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='combine'></a> \n",
    "### 1.3 - Combine data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape =  (1309, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the survived column as y for later and drop it from the train data\n",
    "y_train = df_train_raw.Survived\n",
    "x_train_raw = df_train_raw.drop(['Survived'], axis = 1)\n",
    "\n",
    "# Join the X data from the train and test files, for feature processing\n",
    "X_all = pd.concat((x_train_raw, df_test_raw), axis = 0, ignore_index=True)\n",
    "\n",
    "# Save a copy of X_all for later comparison\n",
    "X_all_original = X_all\n",
    "\n",
    "print('data shape = ', X_all.shape)\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='check-nan'></a> \n",
    "### 1.4 - Check for NaN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-eng'></a> \n",
    "## 2 - Feature engineering\n",
    "<a id='name'></a> \n",
    "### 2.1 - Column \"Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the name column\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Name\":\n",
    "\n",
    "names = X_all.Name\n",
    "\n",
    "print(\"There are \" + str(pd.isnull(names).sum()) + \" nan's in the name column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing names. The next step is to split each name into title, first name and surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  18  unique titles: \n",
      "['Capt' 'Col' 'Don' 'Dona' 'Dr' 'Jonkheer' 'Lady' 'Major' 'Master' 'Miss'\n",
      " 'Mlle' 'Mme' 'Mr' 'Mrs' 'Ms' 'Rev' 'Sir' 'the Countess']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>Surname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>Braund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>Cumings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Laina</td>\n",
       "      <td>Heikkinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>Futrelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>Allen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked Title  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S    Mr   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   Mrs   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  Miss   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   Mrs   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S    Mr   \n",
       "\n",
       "                               FirstName    Surname  \n",
       "0                            Owen Harris     Braund  \n",
       "1  John Bradley (Florence Briggs Thayer)    Cumings  \n",
       "2                                  Laina  Heikkinen  \n",
       "3          Jacques Heath (Lily May Peel)   Futrelle  \n",
       "4                          William Henry      Allen  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(names)):\n",
    "    \n",
    "    full_name = str(names[i])\n",
    "    \n",
    "    # First split: separate the surname from the rest of the name\n",
    "    name_split_1 = full_name.split(sep = ', ', maxsplit=1)\n",
    "    surname = name_split_1[0]\n",
    "    title_and_name = name_split_1[1]\n",
    "    \n",
    "    # Second split: separate the title from the rest of the name\n",
    "    name_split_2 = title_and_name.split(sep = '. ', maxsplit=1)\n",
    "    \n",
    "    title = name_split_2[0]\n",
    "    first_name = name_split_2[1]\n",
    "    \n",
    "    \n",
    "    if(i==0):\n",
    "        titles = np.array(title).reshape(1,1)\n",
    "        first_names = np.array(first_name).reshape(1,1)\n",
    "        surnames = np.array(surname).reshape(1,1)\n",
    "        \n",
    "    else:\n",
    "        titles = np.append(titles, np.array(title).reshape(1,1), axis = 0)\n",
    "        first_names = np.append(first_names, np.array(first_name).reshape(1,1), axis = 0)\n",
    "        surnames = np.append(surnames, np.array(surname).reshape(1,1), axis = 0)\n",
    "        \n",
    "print(\"There are \", np.unique(titles).shape[0], \" unique titles: \")\n",
    "print(str(np.unique(titles)))\n",
    "\n",
    "# add the title, first and last name to X_all\n",
    "X_all['Title'] = titles\n",
    "X_all['FirstName'] = first_names\n",
    "X_all['Surname'] = surnames\n",
    "\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having 18 unique titles could cause trouble for the model if some of them are very infrequent.\n",
    "\n",
    "Let's analyse of the frequency of the titles and respective survival in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7434d14912c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.figure(figsize=(10,5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "title_df = X_all[0:891]\n",
    "title_df['Survived'] = y_train\n",
    "title_df.head()\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "sns.factorplot('Title',data=title_df,hue='Survived',kind='count', size = 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make the job easier for the model, some titles will be grouped together with the most frequent ones\n",
    "\n",
    "X_all['Title'] = X_all['Title'].map({'Don': 'Mr',\n",
    "                                     'Rev': 'Mr', \n",
    "                                     'Jonkheer': 'Mr', \n",
    "                                     'Capt': 'Mr', \n",
    "                                     'Mme': 'Mrs', \n",
    "                                     'Ms': 'Mrs', \n",
    "                                     'Lady': 'Miss', \n",
    "                                     'Sir': 'Mr', \n",
    "                                     'Mlle': 'Mrs', \n",
    "                                     'Mr': 'Mr',\n",
    "                                     'Mrs': 'Mrs',\n",
    "                                     'Miss': 'Miss',\n",
    "                                     'Master': 'Master',\n",
    "                                     'Dr': 'Dr',\n",
    "                                     'Major': 'Major',\n",
    "                                     'Col': 'Col',\n",
    "                                     'the Countess': 'Mrs',\n",
    "                                     'Dona': 'Mrs',\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis and preparation of column \"Age\":\n",
    "# Passenger's age\n",
    "\n",
    "age = X_all.Age\n",
    "print(\"There are \" + str(pd.isnull(age).sum()) + \" nan's in the age column\")\n",
    "\n",
    "#age = age.reshape(age.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are a lot of nan's in the age column and this could be a problem. These nan's will be replaced by -4 and where a value is available for the age, it will be separated in ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The nan's will be replaced with -4\n",
    "age_ = np.zeros_like(age, dtype='float64')\n",
    "\n",
    "for i in range(len(age)):\n",
    "    #print(age[i])\n",
    "    if (pd.isnull(age[i])):\n",
    "        age_[i] = np.float64(-4.0)\n",
    "    else:\n",
    "        age_[i] = np.float64(age[i])\n",
    "\n",
    "# Split the ages into 10 bins\n",
    "bins = np.array([-10.0, 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0]) \n",
    "\n",
    "age_ = age_.reshape(age_.shape[0],)\n",
    "age_bins = np.digitize(age_, bins)\n",
    "\n",
    "# Convert to one hot\n",
    "#age_bins = age_bins.reshape(age_bins.shape[0],)\n",
    "#age_bins_onehot = pd.get_dummies(age_bins)\n",
    "#age_bins_onehot = age_bins_onehot.values\n",
    "\n",
    "# Put the age column back into the dataset\n",
    "X_all.Age = age_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='ticket'></a> \n",
    "### 2.2 - Column \"Ticket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets = X_all.Ticket\n",
    "\n",
    "print(\"There are \" + str(pd.isnull(tickets).sum()) + \" nan's in the ticket column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values in the ticket column. \n",
    "The values will be split into prefix (where available) and number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tickets)):\n",
    "    \n",
    "    # get entry i of column 'ticket'\n",
    "    full_ticket = str(tickets[i])\n",
    "    \n",
    "    # Separate the prefix from the ticket number\n",
    "    ticket_split_1 = full_ticket.split(sep = ' ', maxsplit=1)\n",
    "    \n",
    "    # if there's no prefix, use -999\n",
    "    if(len(ticket_split_1) == 1):\n",
    "        # if there's no prefix, fill with 'nan' so it matches with the dtype of the elemenst in the column (str)\n",
    "        prefix = 'nan'\n",
    "        number = ticket_split_1[0]\n",
    "    else:\n",
    "        prefix = ticket_split_1[0]\n",
    "        number = ticket_split_1[1]\n",
    "    \n",
    "    # append both strings to the respective arrays\n",
    "    if(i==0):\n",
    "        ticket_prefix = np.array(prefix).reshape(1,1)\n",
    "        ticket_number = np.array(number).reshape(1,1)\n",
    "    else:\n",
    "        ticket_prefix = np.append(ticket_prefix, np.array(prefix).reshape(1,1), axis = 0)\n",
    "        ticket_number = np.append(ticket_number, np.array(number).reshape(1,1), axis = 0)\n",
    "\n",
    "# add the ticket prefix and number to X_all\n",
    "X_all['TicketPrefix'] = ticket_prefix\n",
    "X_all['TicketNumber'] = ticket_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cabin'></a> \n",
    "### 2.3 - Column \"Cabin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisys of the 'cabin' column\n",
    "\n",
    "cabins = X_all.Cabin\n",
    "print(\"There are \" + str(pd.isnull(cabins).sum()) + \" nan's in the Cabin column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cabins)):\n",
    "    \n",
    "    # get entry from column 'cabin'\n",
    "    full_cabin = str(cabins[i])\n",
    "    \n",
    "    #print(full_cabin)\n",
    "    \n",
    "    # First, check if the entry i is NaN\n",
    "    if(full_cabin == 'nan'):\n",
    "    # no cabin\n",
    "        reserve = 0\n",
    "        multiple = 0\n",
    "        letter = 'Z'\n",
    "    else:\n",
    "        # passenger has a cabin\n",
    "        reserve = 1\n",
    "        \n",
    "        # check if there is more than one cabin reserved\n",
    "        cabin_split_1 = full_cabin.split(sep = ' ', maxsplit=1)\n",
    "        \n",
    "        if(len(cabin_split_1) > 1):\n",
    "            multiple = 1\n",
    "        else:\n",
    "            multiple = 0\n",
    "        \n",
    "        # check the letter, corresponding to the level in the ship\n",
    "        \n",
    "        #cabin_split_2 = full_cabin.split(sep = '', maxsplit=1)\n",
    "        letter = full_cabin[0]\n",
    "        \n",
    "    #print(full_cabin, ' || reserve = ', reserve, 'multiple = ', multiple, 'letter = ', letter)\n",
    "    #print(cabin_split_1)\n",
    "    #print('======')\n",
    "    \n",
    "    # append both strings to the respective arrays\n",
    "    if(i==0):\n",
    "        cabin_reserve = np.array(reserve).reshape(1,1)\n",
    "        cabin_multiple = np.array(multiple).reshape(1,1)\n",
    "        cabin_letter = np.array(letter).reshape(1,1)\n",
    "    else:\n",
    "        cabin_reserve = np.append(cabin_reserve, np.array(reserve).reshape(1,1), axis = 0)\n",
    "        cabin_multiple = np.append(cabin_multiple, np.array(multiple).reshape(1,1), axis = 0)\n",
    "        cabin_letter = np.append(cabin_letter, np.array(letter).reshape(1,1), axis = 0)\n",
    "\n",
    "# add the ticket prefix and number to X_all\n",
    "X_all['CabinReserve'] = cabin_reserve\n",
    "X_all['CabinMultiple'] = cabin_multiple\n",
    "X_all['CabinLetter'] = cabin_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='encoding'></a> \n",
    "### 2.2 - Variable encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a copy of X_all before encoding\n",
    "X_all_before_encoding = X_all\n",
    "\n",
    "# Convert categorical features into ordinal numbers.\n",
    "\n",
    "\n",
    "def convert_to_int(column):\n",
    "    # convert -column- to integer\n",
    "    \n",
    "    # replace nan's with -999\n",
    "    column[pd.isnull(column)]  = 'NaN'\n",
    "    \n",
    "    # encode the column to integers\n",
    "    le = LabelEncoder()\n",
    "    le.fit(column.unique())\n",
    "    column_int = le.transform(column)\n",
    "    return column_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = convert_to_int(X_all.CabinLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name, Ticket might not be very useful, consider removing later\n",
    "X_all.Sex = convert_to_int(X_all.Sex)\n",
    "X_all.Embarked = convert_to_int(X_all.Embarked)\n",
    "X_all.Title = convert_to_int(X_all.Title)\n",
    "X_all.Surname = convert_to_int(X_all.Surname)\n",
    "X_all.TicketPrefix = convert_to_int(X_all.TicketPrefix)\n",
    "X_all.CabinLetter = convert_to_int(X_all.CabinLetter)\n",
    "\n",
    "#X_all.Name = convert_to_int(X_all.Name)\n",
    "#X_all.Name = convert_to_int(X_all.Name)\n",
    "\n",
    "# Drop Name, Ticket, Cabin, FirstName, TicketNumber\n",
    "X_all = X_all.drop(['Name'], axis = 1)\n",
    "X_all = X_all.drop(['Ticket'], axis = 1)\n",
    "X_all = X_all.drop(['Cabin'], axis = 1)\n",
    "X_all = X_all.drop(['FirstName'], axis = 1)\n",
    "X_all = X_all.drop(['TicketNumber'], axis = 1)\n",
    "\n",
    "#X_all = X_all.drop(['PassengerId'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='before-after'></a> \n",
    "### 2.2 - Before and after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data, before being processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, before variable encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_before_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After variable encoding and dropping some of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='split-data'></a> \n",
    "### 2.2 - Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_all[0:891]\n",
    "X_submission = X_all[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a> \n",
    "## 3 - Model\n",
    "\n",
    "<a id='cv'></a>\n",
    "### 3.1 - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBClassifier()\n",
    "\n",
    "tuned_parameters = [{'eval_metric': ['logloss'],\n",
    "                     'objective': [\"binary:logistic\"],\n",
    "                     'max_depth': [8, 9, 10, 11], \n",
    "                     'n_estimators': [1000], \n",
    "                     'eta': [0.1, 0.2, 0.3],\n",
    "                     'reg_lambda': [0.5, 1.5, 2.5],\n",
    "                     'nthread': [4],\n",
    "                     'subsample': [1],\n",
    "                     'colsample_bytree': [0.3, 0.5, 0.7],\n",
    "                     'alpha': [0.5, 1.5, .5],\n",
    "                     'min_child_weight': [2, 4, 6, 8]}]\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_grid = GridSearchCV(regr, tuned_parameters, cv=n_folds, refit=False, verbose = 1)\n",
    "#regr_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print(regr_grid.best_params_)\n",
    "print(\"Best score:\")\n",
    "print(regr_grid.best_score_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fitting'></a>\n",
    "### 3.2 - Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = regr_grid.cv_results_['mean_test_score']\n",
    "stds = regr_grid.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, regr_grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit using the optimal settings\n",
    "\n",
    "regr_optimum = xgb.XGBClassifier(eval_metric= 'logloss', \n",
    "                         objective= \"binary:logistic\",\n",
    "                         max_depth= 9,\n",
    "                         n_estimators = 1000\n",
    "                         eta= 0.1,\n",
    "                         nthread = 4,\n",
    "                         subsample= 1,\n",
    "                         colsample_bytree= 0.3,\n",
    "                         reg_lambda= 2.5,\n",
    "                         alpha= 0.5,\n",
    "                         min_child_weight= 8\n",
    "                         )\n",
    "\n",
    "regr_optimum.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='submission'></a>\n",
    "## 4 - Submission\n",
    "\n",
    "<a id='sub-file'></a>\n",
    "### 4.1 - File preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_subm = regr_optimum.predict(X_submission)\n",
    "\n",
    "submission_PassengerId = pd.DataFrame(df_test_raw.PassengerId)\n",
    "submission_Survived = pd.DataFrame(y_pred_subm)\n",
    "\n",
    "submission = pd.concat((submission_PassengerId, submission_Survived), axis = 1)\n",
    "submission.columns = ['PassengerId', 'Survived']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='score'></a>\n",
    "### 4.2 - Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression score](https://raw.githubusercontent.com/jgamboias/Titanic/master/logreg_submission.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
