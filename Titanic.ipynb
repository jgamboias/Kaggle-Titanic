{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape = (891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "print(\"Train data shape = \" + str(data_train.shape))\n",
    "\n",
    "original_training_rows = data_train.shape[0]\n",
    "data_train.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape = (418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"test.csv\")\n",
    "print(\"Test data shape = \" + str(data_test.shape))\n",
    "data_test.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for Nan's in the train data\n",
    "\n",
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for Nan's in the test data\n",
    "\n",
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train_y shape: (891, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# separate column \"Survived\" from the others in the train data and save it to use as y\n",
    "data_train_y = data_train.Survived\n",
    "data_train_y = data_train_y.values\n",
    "data_train_y = data_train_y.reshape(data_train_y.shape[0],1)\n",
    "\n",
    "print(\"data_train_y shape: \" + str(data_train_y.shape))\n",
    "print(data_train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x: (1309, 11)\n",
      "[[1 3 'Braund, Mr. Owen Harris' 'male' 22.0 1 0 'A/5 21171' 7.25 nan 'S']\n",
      " [2 1 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)' 'female' 38.0 1\n",
      "  0 'PC 17599' 71.2833 'C85' 'C']\n",
      " [3 3 'Heikkinen, Miss. Laina' 'female' 26.0 0 0 'STON/O2. 3101282' 7.925\n",
      "  nan 'S']\n",
      " [4 1 'Futrelle, Mrs. Jacques Heath (Lily May Peel)' 'female' 35.0 1 0\n",
      "  '113803' 53.1 'C123' 'S']\n",
      " [5 3 'Allen, Mr. William Henry' 'male' 35.0 0 0 '373450' 8.05 nan 'S']]\n"
     ]
    }
   ],
   "source": [
    "# Drop column \"Survived\" from the training data and join the training data with the test data\n",
    "\n",
    "data_train_x = data_train.drop(columns = ['Survived'])\n",
    "\n",
    "data_x = np.concatenate((data_train_x, data_test), axis = 0)\n",
    "\n",
    "print(\"data_x: \" + str(data_x.shape))\n",
    "print(data_x[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepration and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the pclass column\n",
      "[[0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Pclass\":\n",
    "# Passenger's class\n",
    "\n",
    "pclass = data_x[:,1]\n",
    "print(\"There are \" + str(pd.isnull(pclass).sum()) + \" nan's in the pclass column\")\n",
    "pclass_onehot = pd.get_dummies(pclass)\n",
    "pclass_onehot = pclass_onehot.values\n",
    "\n",
    "print(pclass_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the name column\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Name\":\n",
    "# Passenger's name\n",
    "\n",
    "name = data_x[:,2]\n",
    "print(\"There are \" + str(pd.isnull(name).sum()) + \" nan's in the name column\")\n",
    "\n",
    "# First, separate the surname from the rest of the name\n",
    "for i in range(len(name)):\n",
    "    \n",
    "    full_name = str(name[i])\n",
    "    \n",
    "    # First split: separate the surname from the rest of the name\n",
    "    name_split_1 = full_name.split(sep = ', ', maxsplit=1)\n",
    "    surname = name_split_1[0]\n",
    "    title_and_name = name_split_1[1]\n",
    "    \n",
    "    # Second split: separate the title from the rest of the name\n",
    "    name_split_2 = title_and_name.split(sep = '. ', maxsplit=1)\n",
    "    \n",
    "    title = name_split_2[0]\n",
    "    first_name = name_split_2[1]\n",
    "    \n",
    "    \n",
    "    if(i==0):\n",
    "        titles = np.array(title).reshape(1,1)\n",
    "        first_names = np.array(first_name).reshape(1,1)\n",
    "        surnames = np.array(surname).reshape(1,1)\n",
    "        \n",
    "    else:\n",
    "        titles = np.append(titles, np.array(title).reshape(1,1), axis = 0)\n",
    "        first_names = np.append(first_names, np.array(first_name).reshape(1,1), axis = 0)\n",
    "        surnames = np.append(surnames, np.array(surname).reshape(1,1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 different titles: {'Miss', 'Mr', 'Master', 'Mlle', 'Ms', 'Rev', 'Lady', 'Sir', 'Capt', 'Mrs', 'the Countess', 'Don', 'Col', 'Dr', 'Major', 'Jonkheer', 'Mme', 'Dona'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAGfCAYAAAAu+wnJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fb115ee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution for the titles:\n",
    "titles = titles.reshape(titles.shape[0],)\n",
    "titles_list = titles.astype(set)\n",
    "unique_titles = set(titles_list)\n",
    "print(\"There are \" + str(len(unique_titles)) + \" different titles: \" + str(unique_titles))\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "n, bins, patches = plt.hist(titles_list, 18, normed=1, facecolor='g', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Capt  Col  Don  Dona  Dr  Jonkheer  Lady  Major  Master  Miss  Mlle  Mme  \\\n",
      "0     0    0    0     0   0         0     0      0       0     0     0    0   \n",
      "1     0    0    0     0   0         0     0      0       0     0     0    0   \n",
      "2     0    0    0     0   0         0     0      0       0     1     0    0   \n",
      "3     0    0    0     0   0         0     0      0       0     0     0    0   \n",
      "4     0    0    0     0   0         0     0      0       0     0     0    0   \n",
      "\n",
      "   Mr  Mrs  Ms  Rev  Sir  the Countess  \n",
      "0   1    0   0    0    0             0  \n",
      "1   0    1   0    0    0             0  \n",
      "2   0    0   0    0    0             0  \n",
      "3   0    1   0    0    0             0  \n",
      "4   1    0   0    0    0             0  \n"
     ]
    }
   ],
   "source": [
    "# Convert the titles to onehot\n",
    "\n",
    "titles_onehot = pd.get_dummies(titles)\n",
    "print(titles_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the sex column\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]]\n",
      "['male' 'female' 'female' ..., 'male' 'male' 'male']\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Sex\":\n",
    "# Passenger's sex\n",
    "\n",
    "sex = data_x[:,3]\n",
    "print(\"There are \" + str(pd.isnull(sex).sum()) + \" nan's in the sex column\")\n",
    "sex_onehot = pd.get_dummies(sex)\n",
    "sex_onehot = sex_onehot.values\n",
    "print(sex_onehot[:5])\n",
    "\n",
    "print(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 263 nan's in the age column\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Age\":\n",
    "# Passenger's age\n",
    "\n",
    "age = data_x[:,4]\n",
    "print(\"There are \" + str(pd.isnull(age).sum()) + \" nan's in the age column\")\n",
    "age = age.reshape(age.shape[0],1)\n",
    "\n",
    "# Let's not use this one for now, too many nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the sibsp column\n",
      "[[0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"SibSp\":\n",
    "# Number of siblings/spouses aboard\n",
    "\n",
    "sibsp = data_x[:,5]\n",
    "print(\"There are \" + str(pd.isnull(sibsp).sum()) + \" nan's in the sibsp column\")\n",
    "sibsp_onehot = pd.get_dummies(sibsp)\n",
    "sibsp_onehot = sibsp_onehot.values\n",
    "\n",
    "print(sibsp_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Parch\"\n",
    "# Number of parents/children aboard\n",
    "\n",
    "parch = data_x[:,6]\n",
    "parch_onehot = pd.get_dummies(parch)\n",
    "parch_onehot = parch_onehot.values\n",
    "\n",
    "print(parch_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 nan's in the ticket column\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Ticket\":\n",
    "# Ticket number\n",
    "\n",
    "ticket = data_x[:,7]\n",
    "\n",
    "print(\"There are \" + str(pd.isnull(ticket).sum()) + \" nan's in the ticket column\")\n",
    "\n",
    "# Separate the ticket prefix from the ticket number\n",
    "for i in range(len(ticket)):\n",
    "    \n",
    "    full_ticket = str(ticket[i])\n",
    "    ticket_split_1 = full_ticket.split(sep = ' ', maxsplit=1)\n",
    "    \n",
    "    \n",
    "    if(len(ticket_split_1) == 1):\n",
    "        ticket_prefix = 'generic'\n",
    "        ticket_number = ticket_split_1[0]\n",
    "\n",
    "    else:\n",
    "        ticket_prefix = 'non_generic'\n",
    "        ticket_number = ticket_split_1[1]\n",
    "        \n",
    "    \n",
    "    if(i==0):\n",
    "        ticket_prefixes = np.array(ticket_prefix).reshape(1,1)\n",
    "        ticket_numbers = np.array(ticket_number).reshape(1,1)\n",
    "\n",
    "    else:\n",
    "        ticket_prefixes = np.append(ticket_prefixes, np.array(ticket_prefix).reshape(1,1), axis = 0)\n",
    "        ticket_numbers = np.append(ticket_numbers, np.array(ticket_number).reshape(1,1), axis = 0)\n",
    "\n",
    "# For now, only the ticket prefix will be used in the model\n",
    "\n",
    "ticket_prefixes = ticket_prefixes.reshape(age.shape[0],)\n",
    "ticket_prefixes_onehot = pd.get_dummies(ticket_prefixes)\n",
    "ticket_prefixes_onehot = ticket_prefixes_onehot.values\n",
    "\n",
    "print(ticket_prefixes_onehot[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Analysis and preparation of column \"Fare\":\n",
    "# Fare\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1014 nan's in the cabin column, representing passengers that didn't have a cabin\n",
      "[[0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Cabin\":\n",
    "# Cabin\n",
    "\n",
    "cabin = data_x[:,9]\n",
    "print(\"There are \" + str(pd.isnull(cabin).sum()) + \" nan's in the cabin column, representing passengers that didn't have a cabin\")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(cabin)):\n",
    "    \n",
    "    cabin_number = str(cabin[i])\n",
    "    if(cabin_number == 'nan'):\n",
    "        deck = 'N'\n",
    "        \n",
    "    else:\n",
    "        deck = cabin_number[0]\n",
    "        \n",
    "    if(i==0):\n",
    "        cabin_deck = np.array(deck).reshape(1,1)\n",
    "\n",
    "    else:\n",
    "        cabin_deck = np.append(cabin_deck, np.array(deck).reshape(1,1), axis = 0)\n",
    "\n",
    "\n",
    "        \n",
    "cabin_deck = cabin_deck.reshape(cabin_deck.shape[0],)\n",
    "\n",
    "cabin_deck_onehot = pd.get_dummies(cabin_deck)\n",
    "cabin_deck_onehot = cabin_deck_onehot.values\n",
    "        \n",
    "print(cabin_deck_onehot[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C  Q  S\n",
      "0  0  0  1\n",
      "1  1  0  0\n",
      "2  0  0  1\n",
      "3  0  0  1\n",
      "4  0  0  1\n"
     ]
    }
   ],
   "source": [
    "# Analysis and preparation of column \"Embarked\"\n",
    "# Port of embarkation\n",
    "\n",
    "embarked = data_x[:,10]\n",
    "embarked_onehot = pd.get_dummies(embarked)\n",
    "v_onehot = embarked_onehot.values\n",
    "\n",
    "print(embarked_onehot[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the processed data to use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x_final shape: (1309, 49)\n",
      "[[ 0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "pclass_onehot = np.array(pclass_onehot, dtype=float)\n",
    "sex_onehot = np.array(sex_onehot, dtype=float)\n",
    "age = np.array(age, dtype=float)\n",
    "sibsp_onehot = np.array(sibsp_onehot, dtype=float)\n",
    "parch_onehot = np.array(parch_onehot, dtype=float)\n",
    "embarked_onehot = np.array(embarked_onehot, dtype=float)\n",
    "\n",
    "data_x_final = np.concatenate((pclass_onehot, sex_onehot, sibsp_onehot, parch_onehot, titles_onehot, ticket_prefixes_onehot, cabin_deck_onehot), axis = 1)\n",
    "\n",
    "print(\"data_x_final shape: \" + str(data_x_final.shape))\n",
    "print(data_x_final[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Convert data_train_y to one_hot\n",
    "data_train_y_onehot = pd.get_dummies(data_train_y)\n",
    "data_train_y_onehot = data_train_y_onehot.values\n",
    "print(data_train_y_onehot[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "\n",
    "x_train = data_x_final[0:original_training_rows,:]\n",
    "x_test = data_x_final[original_training_rows:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(49, 20, 10, 1), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a logistic regression model\n",
    "\n",
    "from sklearn import linear_model\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_train_y = data_train_y.reshape(data_train_y.shape[0],)\n",
    "\n",
    "#x_train = StandardScaler().fit_transform(x_train)\n",
    "\n",
    "#clf = linear_model.LogisticRegression(C=1e5)\n",
    "#clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(49, 20, 10, 1), random_state=1)\n",
    "\n",
    "clf.fit(x_train, data_train_y_onehot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 836 into shape (418,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4e2c50f7aeff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredicted_passengerid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpredicted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_passengerid\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 836 into shape (418,1)"
     ]
    }
   ],
   "source": [
    "# Apply the trained model to the test set\n",
    "\n",
    "predicted = clf.predict(x_test)\n",
    "\n",
    "predicted_passengerid = data_test.PassengerId.values\n",
    "predicted_passengerid = predicted_passengerid.reshape(predicted_passengerid.shape[0],1)\n",
    "\n",
    "if(predicted_passengerid.shape[1] = 2):\n",
    "    \n",
    "predicted = predicted.reshape(predicted.shape[0],1)\n",
    "\n",
    "predicted_df = np.concatenate((predicted_passengerid ,predicted), axis = 1)\n",
    "predicted_df = pd.DataFrame(predicted_df)\n",
    "predicted_df.columns = ['PassengerId','Survived']\n",
    "predicted_df.head(n=5)\n",
    "\n",
    "predicted_df.to_csv('predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After submitting the file to Kaggle:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logistic Regression score](https://raw.githubusercontent.com/jgamboias/Titanic/master/logreg_submission.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
